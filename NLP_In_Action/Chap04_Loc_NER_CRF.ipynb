{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语料处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据词性标注语料生成用于实体识别的训练语料\n",
    "def tag_line(words):\n",
    "    \"\"\"\n",
    "    根据输入的分词序列（元素为：词 + 词性），标记主体.\n",
    "    words: ['[', '香港/ns', '特别/a', '行政区', ']']\n",
    "    遇到中括号 + ns 标注的，则将中括号内的全部词汇整体提取，否则只提取ns部分\n",
    "    \"\"\"\n",
    "    chars = []  # 记录单个字\n",
    "    tags = []  # 记录实体状态 B M E S O\n",
    "    temp_word = \"\"  # 拼接实体词组（括号内的多个词）\n",
    "    for word in words:\n",
    "        word = word.strip()\n",
    "        w, h = word.split(\"/\")\n",
    "        if temp_word == \"\":\n",
    "            bracket_pos = word.find(\"[\")\n",
    "            # 词中不含 [，则对词进行标注\n",
    "            if bracket_pos == -1:\n",
    "                l = len(w)\n",
    "                if l == 0:\n",
    "                    continue\n",
    "                chars.extend(w)  # 自动将 w转为列表\n",
    "                # 如果词性为 ns， 则标注\n",
    "                if h == \"ns\":\n",
    "                    tags += [\"S\"] if l == 1 else [\"B\"] + [\"M\"] * (l - 2) + [\"E\"]\n",
    "                else:\n",
    "                    tags += [\"O\"] * l\n",
    "            # 词中含有 [\n",
    "            else:\n",
    "                w = w[bracket_pos + 1: ]  # 取中括号之后的部分，而且一般括号都在头部，不会出现漏词\n",
    "                temp_word += w\n",
    "        \n",
    "        # 括号内实体已存在， 则寻找右括号\n",
    "        else:\n",
    "            bracket_pos = word.find(\"]\")\n",
    "            # 未找到右括号，则继续拼接\n",
    "            if bracket_pos == -1:\n",
    "                temp_word += w\n",
    "            # 找到右括号，停止拼接，且标注括号内部分\n",
    "            else:\n",
    "                w = w[: bracket_pos]  # 取括号左边的剩余词\n",
    "                w = temp_word + w  # 最后将拼接词转给 w\n",
    "                h = word[bracket_pos + 1: ]  # 取中括号后面的词性\n",
    "                temp_word = \"\"  # 清空临时词组\n",
    "                l = len(w)\n",
    "                if l == 0:\n",
    "                    continue\n",
    "                chars.extend(w)\n",
    "                if h == \"ns\":  # 说明临时词组是地名\n",
    "                    tags += [\"S\"] if l == 1 else [\"B\"] + [\"M\"] * (l - 2) + [\"E\"]\n",
    "                else:  # 说明临时词组不是地名\n",
    "                    tags += [\"O\"] * l\n",
    "                        \n",
    "    assert temp_word == \"\", \"临时拼接词组不为空\"\n",
    "    return chars, tags              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>香</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>港</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>特</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>别</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>行</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>政</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>区</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>澳</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>门</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>台</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>湾</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char tag\n",
       "52    香   B\n",
       "53    港   M\n",
       "54    特   M\n",
       "55    别   M\n",
       "56    行   M\n",
       "57    政   M\n",
       "58    区   E\n",
       "62    澳   B\n",
       "63    门   E\n",
       "65    台   B\n",
       "66    湾   E"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test!\n",
    "text = \"在/p １９９８年/t 来临/v 之际/f ，/w 我/r 十分/m 高兴/a 地/u 通过/p [中央/n 人民/n 广播/vn 电台/n]nt 、/w [中国/ns 国际/n 广播/vn 电台/n]nt 和/c [中央/n 电视台/n]nt ，/w 向/p 全国/n 各族/r 人民/n ，/w 向/p [香港/ns 特别/a 行政区/n]ns 同胞/n 、/w 澳门/ns 和/c 台湾/ns 同胞/n 、/w 海外/s 侨胞/n ，/w 向/p 世界/n 各国/r 的/u 朋友/n 们/k ，/w 致以/v 诚挚/a 的/u 问候/vn 和/c 良好/a 的/u 祝愿/vn ！/w \"\n",
    "words = text.strip().split()\n",
    "chars, tags = tag_line(words)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(list(zip(chars, tags)), columns=[\"char\", \"tag\"])\n",
    "df[df[\"tag\"] != \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 语料处理函数\n",
    "def corpusHandler(corpusPath):\n",
    "    \"\"\"\n",
    "    利用tag_line函数对语料进行批量处理\n",
    "    params:\n",
    "        corpusPath: 语料地址\n",
    "    \"\"\"\n",
    "    import os\n",
    "    root = os.path.dirname(corpusPath)  # 返回文件所在目录\n",
    "    train_path = os.path.join(root, \"train.txt\")  # 设置训练文件（待写入）\n",
    "    test_path = os.path.join(root, \"test.txt\")  # 设置测试文件（待写入）\n",
    "    \n",
    "    with open(corpusPath, mode=\"r\", encoding=\"UTF-8\") as corpus_f, \\\n",
    "        open(train_path, mode=\"w\", encoding=\"UTf-8\") as train_f, \\\n",
    "        open(test_path, mode=\"w\", encoding=\"UTF-8\") as test_f:\n",
    "        pos = 0\n",
    "        for line in corpus_f:\n",
    "            line = line.strip(\"\\r\\t\\n \")\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            saveObj = test_f if pos % 5 == 0 else train_f  # 用来划分训练集和测试集  4:1\n",
    "            words = line.split()[1:]  # 第一个词是新闻时间，舍弃\n",
    "            if len(words) == 0:\n",
    "                continue\n",
    "            line_chars, line_tags = tag_line(words)\n",
    "            for char, tag in zip(line_chars, line_tags):\n",
    "                line = char + \"\\t\" + tag + \"\\n\"\n",
    "                saveObj.write(line)\n",
    "            saveObj.write(\"\\n\")  # 一行语料处理结束， 输出多写一个 \"\\n\"\n",
    "            pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusPath = \"F:/for learn/Python/NLP_in_Action/chapter-4/data/people-daily.txt\"\n",
    "corpusHandler(corpusPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测结果检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>迈</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>向</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>充</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>满</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>希</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  char y_true y_pred\n",
       "0    迈      O      O\n",
       "1    向      O      O\n",
       "2    充      O      O\n",
       "3    满      O      O\n",
       "4    希      O      O"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/Users/Cigar/Documents/jupyter/NLP_learn/NLP_In_Action/Chap04_save/\"\n",
    "result = pd.read_table(path + \"test.rst\", header=None, names=[\"char\", \"y_true\", \"y_pred\"])\n",
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_states = [\"B\", \"M\", \"E\", \"S\"]\n",
    "y_true = result[\"y_true\"].apply(lambda x: x in recall_states).astype(int)\n",
    "y_pred = result[\"y_pred\"].apply(lambda x: x in recall_states).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    347270\n",
      "           1       0.92      0.85      0.89     11650\n",
      "\n",
      "   micro avg       0.99      0.99      0.99    358920\n",
      "   macro avg       0.96      0.93      0.94    358920\n",
      "weighted avg       0.99      0.99      0.99    358920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
