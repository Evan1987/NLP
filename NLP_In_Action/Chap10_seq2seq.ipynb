{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from _utils import u_constant\n",
    "path = u_constant.PATH_ROOT + \"for learn/Python/NLP_in_Action/chapter-10/seq2seq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vec_path = path + \"tfdata/enc.vec\"\n",
    "decoder_vec_path = path + \"tfdata/dec.vec\"\n",
    "encoder_vocab_path = path + \"tfdata/enc.vocab\"\n",
    "decoder_vocab_path = path + \"tfdata/dec.vocab\"\n",
    "model_path = path + \"model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq:\n",
    "    \n",
    "    def __init__(self, enc_vec_path, dec_vec_path, enc_vocab_path, dec_vec_path, \n",
    "                 model_path, batch_size=1, max_batches=100000, show_epoch=100):\n",
    "        tf.reset_default_graph()\n",
    "        self.encoder_vec = self.load_data_set(enc_vec_path)\n",
    "        self.decoder_vec = self.load_data_set(dec_vec_path)\n",
    "        self.enc_vocab = self.load_vocab(enc_vocab_path)\n",
    "        self.dec_vocab = self.load_vocab(dec_vocab_path)\n",
    "        self.dec_vec2seg = {v: k for k, v in self.dec_vocab.items()}\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.batch_size = batch_size\n",
    "        self.max_batches = max_batches\n",
    "        self.show_epoch = show_epoch\n",
    "        #self.model = tf.contrib.seq2seq.\n",
    "        self.location = [\"杭州\", \"重庆\", \"上海\", \"北京\"]\n",
    "        \n",
    "        \n",
    "    def load_vocab(self, vocab_path):\n",
    "        vocab = {}\n",
    "        with open(vocab_path, \"r\") as f:\n",
    "            for index, word in enumerate(f):\n",
    "                word = word.strip()\n",
    "                vocab[word] = index\n",
    "        return vocab\n",
    "    \n",
    "    def load_data_set(self, file_path):\n",
    "        data = []\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if len(line) > 0:\n",
    "                    seq = [int(i) for i in line.split()]\n",
    "                    data.append(seq)\n",
    "        return data\n",
    "    \n",
    "    def generate_batch(self, train_source, train_targets, batches, sample_num):\n",
    "        batch_inputs = []\n",
    "        batch_targets = []\n",
    "        batch_inputs_length = []\n",
    "        batch_targets_length = []\n",
    "    \n",
    "    def train(self):\n",
    "        train_source = self.encoder_vec\n",
    "        train_targets = self.decoder_vec\n",
    "        \n",
    "        f = open()\n",
    "        \n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 0.8  # 程序最多只能占用指定gpu80%的显存\n",
    "        config.gpu_options.allow_growth = True  \n",
    "        \n",
    "        with tf.Session(config=config) as sess:\n",
    "            ckpt = tf.train.get_checkpoint_state(self.model_path)\n",
    "            if ckpt is not None:\n",
    "                ckpt_path = ckpt.model_checkpoint_path\n",
    "                print(ckpt_path)\n",
    "            else:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            loss_track = []\n",
    "            total_time = 0\n",
    "            \n",
    "            for batch in range(self.max_batches + 1):\n",
    "                start = time.time()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.get_checkpoint_state(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:/for learn/Python/NLP_in_Action/chapter-10/seq2seq/model/nlp_chat.ckpt-203802'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class seq2seq:\n",
    "    def __init__(self, encoder_cell, decoder_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
