{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, model_file, trained=False):\n",
    "        import os\n",
    "        # 存储算法中间结果\n",
    "        self.model_file = model_file\n",
    "        # 状态值集合\n",
    "        # B：词首，M：词中，E：词尾，S：单独成词\n",
    "        self.state_list = [\"B\", \"M\", \"E\", \"S\"]\n",
    "        self.invalid_trans = [(\"B\", \"S\"), \n",
    "                              (\"B\", \"B\"), \n",
    "                              (\"M\", \"B\"),\n",
    "                              (\"M\", \"S\"),\n",
    "                              (\"E\", \"M\"), \n",
    "                              (\"E\", \"E\")]\n",
    "        self.trained = trained\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"从模型文件中读取之前保存的概率\n",
    "        A_dic: 转移概率\n",
    "        B_dic: 发射概率\n",
    "        Pi_dic: 初始概率\n",
    "        \"\"\"\n",
    "        import pickle\n",
    "        with open(model_file, mode=\"rb\") as f:\n",
    "            self.A_dic, self.B_dic, self.Pi_dic = pickle.load(f)\n",
    "        f.close()\n",
    "    \n",
    "    def init_model(self):\n",
    "        \"\"\"初始化各概率\n",
    "        A_dic: 转移概率\n",
    "        B_dic: 发射概率\n",
    "        Pi_dic: 初始概率\n",
    "        \"\"\"\n",
    "        self.A_dic = {}\n",
    "        self.B_dic = {}\n",
    "        self.Pi_dic = {}\n",
    "        for state in self.state_list:\n",
    "            self.A_dic[state] = {s: 0.0 for s in self.state_list}\n",
    "            self.B_dic[state] = {}\n",
    "            self.Pi_dic[state] = 0\n",
    "    \n",
    "    def _makeLabel(self, word):\n",
    "        \"\"\"\n",
    "        给单一单词的各个字状态打标，返回一个状态列表\n",
    "        \"\"\"\n",
    "        length = len(word)\n",
    "        if length == 1:\n",
    "            # 单字成词，因此返回 S\n",
    "            return [\"S\"]\n",
    "        else:\n",
    "            # 多字词，除去词首 B， 词尾 E，其余均为 M\n",
    "            return [\"B\"] + [\"M\"] * (length - 2) + [\"E\"]\n",
    "        \n",
    "    def _check_trans(self):\n",
    "        \"\"\"\n",
    "        检查统计后的转移矩阵参数是否正确，不合理的转移是否出现\n",
    "        \"\"\"\n",
    "        for former, latter in self.invalid_trans:\n",
    "            check_value = self.A_dic[former][latter]\n",
    "            error_text = \"invalid trans between %s and %s with P: %.4f\" % (former, latter, check_value)\n",
    "            assert check_value == 0.0, error_text\n",
    "            \n",
    "    \n",
    "    def train(self, path):\n",
    "        \"\"\"\n",
    "        从已经分好词的语料中，学习转移概率，发射概率，初始概率\n",
    "        \"\"\"\n",
    "        self.init_model()\n",
    "        # 统计各状态出现次数，便于计算 pi。初始化为 0\n",
    "        count_dic = {s: 0 for s in self.state_list}\n",
    "        line_num = 0\n",
    "        vocabs = set()\n",
    "        with open(path, encoding=\"UTF-8\") as f:\n",
    "            for line in f:\n",
    "                line_num += 1\n",
    "                line = line.strip()\n",
    "                if len(line) == 0:\n",
    "                    continue\n",
    "                character_list = [i for i in line if i != ' ']\n",
    "                \n",
    "                line_list = line.split()\n",
    "                line_state_list = []\n",
    "                for word in line_list:\n",
    "                    state = self._makeLabel(word)\n",
    "                    line_state_list.extend(state)\n",
    "                \n",
    "                assert len(character_list) == len(line_state_list), \"字数量与状态数量不一致\"\n",
    "                \n",
    "                former_state = None\n",
    "                for index, (state, char) in enumerate(zip(line_state_list, character_list)):\n",
    "                    count_dic[state] += 1\n",
    "                    # 句首识别与统计，初始概率计算相关，一行只会有一个\n",
    "                    if index == 0:\n",
    "                        self.Pi_dic[state] += 1\n",
    "                    # 其他概率的统计\n",
    "                    else:\n",
    "                        ## former_state -> state 计数 + 1\n",
    "                        self.A_dic[former_state][state] += 1\n",
    "                        ## state -> char 计数 + 1\n",
    "                        try:\n",
    "                            self.B_dic[state][char] += 1\n",
    "                        except KeyError:\n",
    "                            self.B_dic[state][char] = 1\n",
    "                    former_state = state\n",
    "        # 最后对统计计数进行归一化，得到概率：\n",
    "        self.Pi_dic = {k: v * 1.0 / line_num for k, v in self.Pi_dic.items()}\n",
    "        self.A_dic = {k: {k1: v1 / count_dic[k] for k1, v1 in v.items()} for k, v in self.A_dic.items()}\n",
    "        ## 对发射概率 + 1做平滑\n",
    "        self.B_dic = {k: {k1: (v1 + 1) / count_dic[k] for k1, v1 in v.items()} for k, v in self.B_dic.items()}\n",
    "        \n",
    "        self._check_trans()\n",
    "        \n",
    "        import dill as pickle\n",
    "        with open(self.model_file, mode=\"wb\") as f:\n",
    "            pickle.dump([self.A_dic, self.B_dic, self.Pi_dic], f, pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "        \n",
    "        return self \n",
    "        \n",
    "    def viterbi(self, text, states, start_p, trans_p, emit_p):\n",
    "        \"\"\"\n",
    "        利用维特比算法对给定的text进行解码（state），得到最大似然的隐藏状态序列（分词状态）\n",
    "        start_p: 起始状态概率 (Pi_dic) state: P\n",
    "        trans_p: 状态转移概率 (A_dic) state: {state: P}\n",
    "        emit_p: 发射概率 (B_dic) state: {word: P}\n",
    "        \"\"\"\n",
    "        import itertools\n",
    "        V = []  # 记录各步各状态对应的概率\n",
    "        path = {}  # 记录到各点的最优路径\n",
    "        vocabs = set(list(itertools.chain.from_iterable([list(v.keys()) for v in emit_p.values()])))  # 发射词汇\n",
    "        \n",
    "        # 前溯过程\n",
    "        for t, w in enumerate(text):\n",
    "            V.append({})\n",
    "            # 初始化\n",
    "            if t == 0:\n",
    "                for y in states:\n",
    "                    V[t][y] = start_p[y] * emit_p[y].get(w, 0)\n",
    "                    path[y] = [y]\n",
    "            else:\n",
    "                ## 如果出现了未知字则设置发射概率为 1.0\n",
    "                neverSeen = w not in vocabs\n",
    "                emitP = emit_p[y].get(w, 0) if not neverSeen else 1.0\n",
    "                new_path = {}\n",
    "                \n",
    "                ## 针对句子最后一字的状态选择，只能是词尾或单独成词\n",
    "                valid_states = states if t < len(text) - 1 else [\"E\", \"S\"]\n",
    "                for y in valid_states:\n",
    "                    max_value = 0.0\n",
    "                    max_y0 = \"\"\n",
    "                    for y0 in states:\n",
    "                        prob = V[t - 1][y0] * trans_p[y0].get(y, 0) * emitP\n",
    "                        if prob > max_value:\n",
    "                            max_value = prob\n",
    "                            max_y0 = y0\n",
    "                    V[t][y] = max_value  # 记录到达当前状态的最大概率\n",
    "                    new_path[y] = path[max_y0] + [y]  # 记录到达当前状态的之前最优路径\n",
    "                path = new_path  # 重新赋值给最优路径记录\n",
    "                \n",
    "        # 获取终点的最优状态，回溯最优路径\n",
    "        (_, final_state) = max([(V[-1][y], y) for y in [\"E\", \"S\"]])\n",
    "        return path[final_state]\n",
    "    \n",
    "    def cut(self, text):\n",
    "        import os\n",
    "        # 如果需要 load已有模型，则此处load\n",
    "        if self.trained:\n",
    "            self.load_model()\n",
    "        \n",
    "        char_states = self.viterbi(text, self.state_list, self.Pi_dic, self.A_dic, self.B_dic)\n",
    "        begin, next_ = 0, 0\n",
    "        for i, (state, char) in enumerate(zip(char_states, text)):\n",
    "            if state == \"B\":\n",
    "                begin = i\n",
    "            elif state == \"E\":\n",
    "                yield text[begin: (i + 1)]\n",
    "                next_ = i + 1\n",
    "            elif state == \"S\":\n",
    "                yield char\n",
    "                next_ = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:/Users/Cigar/Documents/jupyter/NLP_learn/NLP_In_Action/Chap03_save/model\"\n",
    "corpus_path = \"F:/for learn/Python/NLP_in_Action/chapter-3/data/trainCorpus.txt_utf8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.HMM at 0x24e335deb70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = HMM(model_file=model_path, trained=False)\n",
    "hmm.train(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['这是', '一个', '非常', '棒的', '方案']\n"
     ]
    }
   ],
   "source": [
    "print(list(hmm.cut(\"这是一个非常棒的方案\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
